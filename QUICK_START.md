# Slurm-K8s í†µí•© ì‹œìŠ¤í…œ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## 30ë¶„ ë§Œì— ì‹œì‘í•˜ê¸°

### 1ë‹¨ê³„: ìŠ¤í¬ë¦½íŠ¸ ì„¤ì¹˜ (5ë¶„)

```bash
# ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ~/slurm-k8s-integration
cd ~/slurm-k8s-integration

# ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ë¥¼ /usr/local/binìœ¼ë¡œ ë³µì‚¬
sudo cp slurm_k8s_prolog.sh /usr/local/bin/
sudo cp slurm_k8s_epilog.sh /usr/local/bin/
sudo cp job_validator.sh /usr/local/bin/
sudo cp job_watcher.sh /usr/local/bin/

# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
sudo chmod +x /usr/local/bin/slurm_k8s_*.sh
sudo chmod +x /usr/local/bin/job_*.sh

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
sudo mkdir -p /var/log/slurm-k8s
sudo chown slurm:slurm /var/log/slurm-k8s
```

### 2ë‹¨ê³„: Slurm ì„¤ì • ìˆ˜ì • (10ë¶„)

```bash
# ê¸°ì¡´ ì„¤ì • ë°±ì—…
sudo cp /etc/slurm/slurm.conf /etc/slurm/slurm.conf.backup

# ì„¤ì • íŒŒì¼ í¸ì§‘
sudo nano /etc/slurm/slurm.conf
```

**ì¶”ê°€í•  ë‚´ìš©:**
```conf
# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Core_Memory
SchedulerParameters=bf_max_job_test=100,bf_interval=30

# ìš°ì„ ìˆœìœ„ ì„¤ì •
PriorityType=priority/multifactor
PriorityWeightAge=1000
PriorityWeightFairshare=10000
PriorityWeightJobSize=1000

# Prolog/Epilog
Prolog=/usr/local/bin/slurm_k8s_prolog.sh
Epilog=/usr/local/bin/slurm_k8s_epilog.sh
PrologEpilogTimeout=600
```

**ì„¤ì • ì ìš©:**
```bash
sudo systemctl restart slurmctld
sudo systemctl status slurmctld
```

### 3ë‹¨ê³„: NAS ë””ë ‰í† ë¦¬ ì¤€ë¹„ (2ë¶„)

```bash
# Job ì œì¶œ/ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p /mnt/test-k8s/slurm-jobs/{submit,processed,failed}
mkdir -p /mnt/test-k8s/results
mkdir -p /mnt/test-k8s/scripts

# ê¶Œí•œ ì„¤ì •
chmod 755 /mnt/test-k8s/slurm-jobs/*
chmod 755 /mnt/test-k8s/results
```

### 4ë‹¨ê³„: Job Watcher ì„œë¹„ìŠ¤ ì‹œì‘ (3ë¶„)

```bash
# systemd ì„œë¹„ìŠ¤ íŒŒì¼ ìƒì„±
sudo tee /etc/systemd/system/slurm-job-watcher.service <<EOF
[Unit]
Description=Slurm Job Watcher
After=network.target

[Service]
Type=simple
ExecStart=/usr/local/bin/job_watcher.sh
Restart=always
User=slurm

[Install]
WantedBy=multi-user.target
EOF

# ì„œë¹„ìŠ¤ ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl enable slurm-job-watcher
sudo systemctl start slurm-job-watcher
sudo systemctl status slurm-job-watcher
```

### 5ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì¤€ë¹„ (5ë¶„)

```bash
# ê°„ë‹¨í•œ Alpine ì´ë¯¸ì§€ íƒœê¹… (ì´ë¯¸ ìˆë‹¤ë©´ ìŠ¤í‚µ)
nerdctl-safe pull alpine:latest
nerdctl-safe tag alpine:latest nas-hub.local:5407/alpine:latest
nerdctl-safe push nas-hub.local:5407/alpine:latest

# í™•ì¸
nerdctl-safe images | grep nas-hub.local:5407
```

### 6ë‹¨ê³„: ì²« Job ì‹¤í–‰ (5ë¶„)

```bash
# í…ŒìŠ¤íŠ¸ Job íŒŒì¼ ìƒì„±
cat > /mnt/test-k8s/slurm-jobs/submit/hello-world.sh <<'EOF'
#!/bin/bash
#SBATCH --job-name=hello-world
#SBATCH --cpus-per-task=1
#SBATCH --mem=512M
#SBATCH --time=00:02:00
#SBATCH --output=/mnt/test-k8s/results/hello-%j.out
#SBATCH --error=/mnt/test-k8s/results/hello-%j.err
#K8S_IMAGE=nas-hub.local:5407/alpine:latest

echo "=========================================="
echo "Hello from Slurm-K8s Integration!"
echo "Job ID: $SLURM_JOB_ID"
echo "Hostname: $(hostname)"
echo "Date: $(date)"
echo "=========================================="

# ê°„ë‹¨í•œ ê³„ì‚°
for i in {1..10}; do
  echo "Iteration $i: $(date +%s)"
  sleep 1
done

echo "Job completed successfully!"
EOF
```

**Job ì œì¶œ í™•ì¸:**
```bash
# Job Watcherê°€ ìë™ìœ¼ë¡œ ì œì¶œ (ë˜ëŠ” ì§ì ‘ ì œì¶œ)
# sbatch /mnt/test-k8s/slurm-jobs/submit/hello-world.sh

# Job ìƒíƒœ í™•ì¸
watch -n 2 'squeue; echo "---"; kubectl get pods -l app=slurm-job'
```

---

## ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤í–‰ í›„ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

### âœ… ì‹œìŠ¤í…œ ìƒíƒœ
```bash
# Slurm ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘
systemctl is-active slurmctld

# Job Watcher ì‹¤í–‰ ì¤‘
systemctl is-active slurm-job-watcher

# K8s í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ ê°€ëŠ¥
kubectl cluster-info

# NAS ë§ˆìš´íŠ¸ í™•ì¸
mountpoint /mnt/test-k8s
```

### âœ… Job ì›Œí¬í”Œë¡œìš°
```bash
# 1. Jobì´ íì— ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸
squeue

# 2. K8s Podê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
kubectl get pods -l app=slurm-job

# 3. Job ì™„ë£Œ í›„ ê²°ê³¼ í™•ì¸
ls -lh /mnt/test-k8s/results/

# 4. ë¡œê·¸ í™•ì¸
tail -f /var/log/slurm-k8s/prolog_*.log
tail -f /var/log/slurm-k8s/epilog_*.log
```

---

## ë‹¤ìŒ ë‹¨ê³„

### ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©

**GPU Job ì‹¤í–‰:**
```bash
cat > gpu_job.sh <<'EOF'
#!/bin/bash
#SBATCH --job-name=gpu-test
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --mem=8G
#SBATCH --time=01:00:00
#SBATCH --output=/mnt/test-k8s/results/gpu-%j.out
#K8S_IMAGE=nas-hub.local:5407/pytorch:2.0-cuda11.8

nvidia-smi
python /mnt/test-k8s/scripts/train.py
EOF

sbatch gpu_job.sh
```

**Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:**
```bash
# /mnt/test-k8s/scripts/example.py ìƒì„±
cat > /mnt/test-k8s/scripts/example.py <<'EOF'
import time
import os

print(f"Job ID: {os.environ.get('SLURM_JOB_ID')}")
print(f"Starting computation...")

for i in range(10):
    print(f"Step {i+1}/10")
    time.sleep(1)

print("Computation complete!")
EOF

# Job íŒŒì¼ ìƒì„±
cat > python_job.sh <<'EOF'
#!/bin/bash
#SBATCH --job-name=python-test
#SBATCH --cpus-per-task=2
#SBATCH --mem=2G
#SBATCH --output=/mnt/test-k8s/results/python-%j.out
#K8S_IMAGE=nas-hub.local:5407/python:3.11

python3 /mnt/test-k8s/scripts/example.py
EOF

sbatch python_job.sh
```

---

## ë¬¸ì œ ë°œìƒ ì‹œ

### ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

**1. Jobì´ ì œì¶œë˜ì§€ ì•ŠìŒ**
```bash
# Job Watcher ë¡œê·¸ í™•ì¸
sudo journalctl -u slurm-job-watcher -f

# ìˆ˜ë™ìœ¼ë¡œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
/usr/local/bin/job_validator.sh /path/to/job.sh
```

**2. Podê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ**
```bash
# Prolog ë¡œê·¸ í™•ì¸
tail -100 /var/log/slurm-k8s/prolog_*.log

# K8s ë¦¬ì†ŒìŠ¤ í™•ì¸
kubectl get nodes
kubectl get events --sort-by='.lastTimestamp' | tail -20
```

**3. ê²°ê³¼ íŒŒì¼ì´ ì—†ìŒ**
```bash
# Epilog ë¡œê·¸ í™•ì¸
tail -100 /var/log/slurm-k8s/epilog_*.log

# NAS ê²½ë¡œ í™•ì¸
ls -lh /mnt/test-k8s/results/
```

---

## ë„ì›€ë§

**ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜:**
- Prolog: `/usr/local/bin/slurm_k8s_prolog.sh`
- Epilog: `/usr/local/bin/slurm_k8s_epilog.sh`
- Validator: `/usr/local/bin/job_validator.sh`
- Watcher: `/usr/local/bin/job_watcher.sh`

**ëª¨ë“  ë¡œê·¸ ìœ„ì¹˜:**
- Slurm: `/var/log/slurm/slurmctld.log`
- í†µí•© ì‹œìŠ¤í…œ: `/var/log/slurm-k8s/*.log`
- Job Watcher: `journalctl -u slurm-job-watcher`

**ìœ ìš©í•œ ëª…ë ¹ì–´:**
```bash
# ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í•œëˆˆì— ë³´ê¸°
echo "=== Slurm ===" && sinfo && \
echo "=== Jobs ===" && squeue && \
echo "=== K8s Pods ===" && kubectl get pods -l app=slurm-job && \
echo "=== Recent Results ===" && ls -lht /mnt/test-k8s/results/ | head -5
```

---

**ì„¤ì¹˜ ì™„ë£Œ! ğŸ‰**

ì´ì œ Slurm-K8s í†µí•© ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.
`/mnt/test-k8s/slurm-jobs/submit/`ì— Job íŒŒì¼ì„ ë³µì‚¬í•˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤!
